{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ea7c7cd-b616-412f-b73b-2811687aa2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"ba962c0c-522d-4be4-90b2-9d8fbb5b3de0\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    function drop(id) {\n",
       "      const view = Bokeh.index.get_by_id(id)\n",
       "      if (view != null) {\n",
       "        view.model.document.clear()\n",
       "        Bokeh.index.delete(view)\n",
       "      }\n",
       "    }\n",
       "\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null) {\n",
       "      drop(id)\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim()\n",
       "            drop(id)\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"ba962c0c-522d-4be4-90b2-9d8fbb5b3de0\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.3.0.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "          for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"ba962c0c-522d-4be4-90b2-9d8fbb5b3de0\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"ba962c0c-522d-4be4-90b2-9d8fbb5b3de0\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.3.0.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"ba962c0c-522d-4be4-90b2-9d8fbb5b3de0\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bokeh.io\n",
    "import bokeh.plotting\n",
    "bokeh.io.output_notebook()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from pathlib import Path  \n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b232d08-db40-44b6-95ff-fce5b5a6941d",
   "metadata": {},
   "source": [
    "**PRE-DATA PROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "881c2417-0084-4f77-9173-b3461c17e978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_format(raw_file):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes in raw csv file and converts it to usable format\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(raw_file)\n",
    "\n",
    "    df.columns\n",
    "\n",
    "    last_num = list(df['location'].values)[-1][3:]\n",
    "\n",
    "    dict_fish = {}\n",
    "\n",
    "    for num in range(1, int(last_num) + 1):\n",
    "        if num < 10:\n",
    "            num = '0' + str(num)\n",
    "            \n",
    "        if list(df['location'].values)[0][0] == 'L':\n",
    "            location = \"Loc\" + str(num)\n",
    "            dict_fish['FISH' + str(num)] = list(df.loc[df['location'] == location, \"lardist\"].values)\n",
    "            \n",
    "        elif list(df['location'].values)[0][0] == 'N':\n",
    "            location = \"Noc\" + str(num)\n",
    "            dict_fish['FISH' + str(num)] = list(df.loc[df['location'] == location, \"lardist\"].values)\n",
    "    \n",
    "    return pd.DataFrame(dict_fish)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a787e86e-255a-4c06-ae94-bd4206659545",
   "metadata": {},
   "source": [
    "**SPECIFYING CATEGORIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba7f66df-37c1-4354-b35f-d97a6e42ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categories(genotype_file, fish_types = ['wt', 'het', 'null']):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Makes a dictionary matching each fish to its type\n",
    "    \n",
    "    Parameters:\n",
    "      genotype_file (csv file): genotype data for fish (assuming order is wt, het, null; if order is different, input fish types in order into fish_types kwarg)\n",
    "      fish_types (list) : genotypes of fish (fish_type = ['wt', 'het', 'null'] is set unless specificied)\n",
    "    \n",
    "    Returns \n",
    "    dictionary (dict) : dictionary with each fish type\n",
    "    i.e. {WT : [FISH1, FISH5, FISh6, FISH7], HET : [FISH9, FISH10], NULL : [FISH16, FISH7]}\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(genotype_file)\n",
    "    \n",
    "    dictionary = {}\n",
    "\n",
    "    for i, ele in enumerate(df.columns):\n",
    "        dict_key = ele\n",
    "        values = []\n",
    "        for index, val in enumerate(df[ele]):\n",
    "            if val > 0:\n",
    "                values.append('FISH' + str(int(val)))\n",
    "            dictionary[fish_types[i]] = values\n",
    "\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffdabbd-6bcc-4722-97b8-4c7b5d710a1e",
   "metadata": {},
   "source": [
    "**CALCULATING THRESHHOLD CUTOFF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9af1559f-5f32-46ca-a6f8-4a338f1a04f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_thresh(baseline_file, genotype_file, categories_dictionary,  p = 99):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Calculates percentile value for WT baseline fish\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "      baseline_file (csv file) : file for baseline \n",
    "      p (int) : Integer percentile to calculate, default = 99\n",
    "      genotype_file (csv file) : file with fish genotype data \n",
    "    \n",
    "    Returns\n",
    "    \n",
    "      np.percentile( WT_values, p) (int) : calculted percentile value\n",
    "      \n",
    "    \"\"\"\n",
    "        \n",
    "    wt_key = list(categories_dictionary.keys())[0]\n",
    "    \n",
    "    WT_values = []\n",
    "    \n",
    "    df = pd.read_csv(baseline_file)\n",
    "    \n",
    "    for ele in df.columns:\n",
    "        if ele in categories_dictionary[wt_key]:\n",
    "            for index2, i in enumerate(df[ele]):\n",
    "                if index2 < 600:\n",
    "                    WT_values.append(i)\n",
    "                    \n",
    "    return np.percentile(WT_values, p) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5541c352-2443-46bb-a053-22251c20eef0",
   "metadata": {},
   "source": [
    "**THRESHHOLD PROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e03bbeee-42ac-42af-bd0c-707d032bd262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresh_data_processing(file, baseline_file, genotype_file, p = 99, fish_types = ['wt', 'het', 'null']):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    For each fish calculates the number of values above the calculated threshold (Time in Seizure (s)), the length of each bout of continuous values above threshold (# seizures), \n",
    "    average length of all seizures (average seizure length), and creates a dictionary matching each condition with a tuple indicating the time count, seizure count, and \n",
    "    average seizure length for each fish\n",
    "\n",
    "    Parameters:\n",
    "       file (csv file) : data for one condition\n",
    "       p (int) : Integer percentile to calculate, default = 99\n",
    "       genotype_file (csv file) : file with fish genotype data\n",
    "    \n",
    "    Returns\n",
    "       output_dict (dict) : dictionary sorting fish time in sezire/seizue count/avg seizure lenvalues for each fish\n",
    "       i.e. {{'FISH1' : (1, 1, 1), 'FISH2' : (0, 1, 0)}\n",
    "       \n",
    "    \"\"\"\n",
    "\n",
    "    categories_dictionary = categories(genotype_file)\n",
    "    \n",
    "    thresh = calc_thresh(baseline_file, gen, categories_dictionary)\n",
    "        \n",
    "    df = pd.read_csv(file)\n",
    "    output_dict = {}\n",
    "        \n",
    "    for index1, ele in enumerate(df.columns):\n",
    "            \n",
    "        if ele[0].upper() != 'F': \n",
    "            continue\n",
    "\n",
    "        movement_list = list(np.where(list(df[ele][0:600]) > thresh, 1, 0))\n",
    "\n",
    "        time_in_seizure = sum(movement_list)\n",
    "                    \n",
    "        for index, num in enumerate(movement_list):\n",
    "\n",
    "            if index != len(movement_list)-1 and num == 1 and movement_list[index+1] == 1:\n",
    "                movement_list[index] = 0\n",
    "\n",
    "        num_seizures = sum(movement_list)\n",
    "\n",
    "        if num_seizures != 0:\n",
    "\n",
    "            average_seizure_length = time_in_seizure / num_seizures\n",
    "\n",
    "        else:\n",
    "\n",
    "            average_seizure_length = 0\n",
    "        \n",
    "        output_dict[ele] = (time_in_seizure, num_seizures, average_seizure_length) \n",
    "                \n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c566c4-c525-4c39-94a1-d263a3332ac7",
   "metadata": {},
   "source": [
    "**LOAD AND COMPILE DATAFRAME**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dcc8af0-8ac7-4dfc-9e20-f7d2eef1cab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_df(base, water, one, two, five):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Compiles the dictionaries from all four conditions into one dataframe\n",
    "\n",
    "    Parameters:\n",
    "    one, two, five, base, water (dictionary) : four dictionaries, one for each contition\n",
    "\n",
    "    Returns:\n",
    "    comb_df (df): combined dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    measurement = ['Time in Seizure (s)', '# Seizures', 'Average Seizure Length']\n",
    "\n",
    "    base_df = pd.DataFrame(base)\n",
    "    base_df.insert(0, 'Measurement', measurement)\n",
    "    base_df.insert(0, 'Condition', 'Baseline')\n",
    "\n",
    "    water_df = pd.DataFrame(water)\n",
    "    water_df.insert(0, 'Measurement', measurement)\n",
    "    water_df.insert(0, 'Condition', 'Water')\n",
    "\n",
    "    one_df = pd.DataFrame(one)\n",
    "    one_df.insert(0, 'Measurement', measurement)\n",
    "    one_df.insert(0, 'Condition', '1M')\n",
    "\n",
    "    two_df = pd.DataFrame(two)\n",
    "    two_df.insert(0, 'Measurement', measurement)\n",
    "    two_df.insert(0, 'Condition', '2M')\n",
    "\n",
    "    five_df = pd.DataFrame(five)\n",
    "    five_df.insert(0, 'Measurement', measurement)\n",
    "    five_df.insert(0, 'Condition', '5M')\n",
    "\n",
    "    comb_df = pd.concat([base_df, water_df, one_df, two_df, five_df], ignore_index=True)\n",
    "    \n",
    "    return comb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674378fb-beb8-4ea2-a77c-7c9a0b1301b5",
   "metadata": {},
   "source": [
    "**SEPARATING DFS BY GENOTYPE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db09ad60-f176-41f9-8aaf-266599a26d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_genotypes(comb_df, categories_dictionary):\n",
    "\n",
    "    \"\"\"\n",
    "    Separates the combined dataframe into a list of dictionaries, one for each condition\n",
    "\n",
    "    Parameters:\n",
    "    comb_df (df) : combined datafram\n",
    "    catagories dictionary (dict) : catagories separating each fish by conditions\n",
    "\n",
    "    Returns:\n",
    "    all_dicts (list) : list of dictionaries \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    all_dicts = []\n",
    "    cat_dict = {}\n",
    "\n",
    "    for diction in categories_dictionary:\n",
    "        cat_dict.clear\n",
    "        cat_dict = {'Condition' : list(comb_df['Condition'].values), 'Measurement' : list(comb_df['Measurement'].values)}\n",
    "        for fish in categories_dictionary[diction]:\n",
    "            if len(fish) <= 5:\n",
    "                fish = fish[:4] + '0' + fish[len(fish)-1]\n",
    "            cat_dict[fish] = list(comb_df[fish].values)\n",
    "            \n",
    "        all_dicts.append(cat_dict)\n",
    "    \n",
    "    return all_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ea37e2-48e0-4ff8-a840-0e7418a0c1cf",
   "metadata": {},
   "source": [
    "**ADDING Z-SCORE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4722fde-98ae-4040-9e16-a2c7d378385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_WT_vals(wt_df):\n",
    "\n",
    "    \"\"\"\n",
    "    Obtains the time in seizure, seizure count, and average seizure length counts for all fish in the wildtype baseline condition (controls)\n",
    "\n",
    "    Parameters:\n",
    "    wt_df (df): dataframe for WT fish\n",
    "\n",
    "    Returns:\n",
    "    time_mean_sd (dict): dictionary matching each condition to a tuple with the (standard deviation, mean) for the seizure count from each WT-baseline fish \n",
    "    (i.e. '1M': (22, 4), '5M': (52, 138), 'Baseline': (49, 35), 'Water': (12, 18)}\n",
    "    seizure_count_mean_sd dict) : does the same as previous except calculates from number of seizure values\n",
    "    avg_mean_seizure len (dict) : does the same as previous except calculates from average seizure length values\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    WT_dict_time_count = {}\n",
    "    WT_dict_seizure_count = {}\n",
    "    WT_dict_avg_seizure_len = {}\n",
    "    \n",
    "    conditions = ['Baseline', 'Water', '1M', '2M', '5M']\n",
    "\n",
    "    dicts = [WT_dict_time_count, WT_dict_seizure_count, WT_dict_avg_seizure_len]\n",
    "    \n",
    "    for condition in conditions:\n",
    "        for i, measurement in enumerate(['Time in Seizure (s)', '# Seizures', 'Average Seizure Length']):\n",
    "            x = wt_df.loc[wt_df['Condition'] == condition]\n",
    "            y = x.loc[x['Measurement'] == measurement].values\n",
    "            y_list = y.tolist()[0][2:]\n",
    "            z_score = list(zscore(y_list))\n",
    "\n",
    "            y_updated = []\n",
    "            ## removing outliers\n",
    "            for yval, zval in zip(y_list, z_score):\n",
    "                if zval >= 3.4 or zval <= -3.4:\n",
    "                    print('hi')\n",
    "                    pass\n",
    "                y_updated.append(yval)\n",
    "                    \n",
    "            dicts[i]['WT_' + condition] = y_updated\n",
    "\n",
    "    time_mean_sd = {}\n",
    "\n",
    "    for condition, val_list in zip(conditions, list(WT_dict_time_count.values())):\n",
    "        time_mean_sd[condition] = (np.std(val_list, ddof=1), np.mean(val_list))\n",
    "    \n",
    "    #for number of seizures\n",
    "    \n",
    "    seizure_count_mean_sd = {}\n",
    "        \n",
    "    for condition, val_list in zip(conditions, list(WT_dict_seizure_count.values())):\n",
    "        seizure_count_mean_sd[condition] = (np.std(val_list, ddof=1), np.mean(val_list))\n",
    "        \n",
    "    #for average seizure length\n",
    "        \n",
    "    avg_mean_sd = {}\n",
    "\n",
    "    values = []\n",
    "\n",
    "    for condition, val_list in zip(conditions, list(WT_dict_avg_seizure_len.values())):\n",
    "        avg_mean_sd[condition] = (np.std(val_list, ddof=1), np.mean(val_list))\n",
    "\n",
    "    return time_mean_sd, seizure_count_mean_sd, avg_mean_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ab504db-64cf-417b-8fb3-9d0ee22039a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_z_score(condition_dictionary, wt_df):\n",
    "\n",
    "    \"\"\"\n",
    "    Adds the z-score for the time in seizure, # seizures, and average seizure length count for each fish under one condition\n",
    "\n",
    "    Parameters:\n",
    "    condition_dictionary (dict): dictionary for one condition, generated from separate_genotypes function\n",
    "    wt_df (df) : df for WT fish\n",
    "\n",
    "    Returns:\n",
    "    final_dictionary (dict) : new dictionary with z-scores\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    time_mean_sd, seizure_count_mean_sd, avg_mean_sd = get_WT_vals(wt_df)\n",
    "    \n",
    "    final_dictionary = {}\n",
    "    \n",
    "    final_dictionary['Condition'] = ['Baseline']*6 + ['Water']*6 + ['1M']*6 + ['2M']*6 + ['5M']*6 \n",
    "\n",
    "    final_dictionary['Measurement'] = ['Time in Seizure (s)', 'Time in Seizure (s) Z-Score', '# Seizures',  '# Seizures Z-score', 'Average Seizure Length',  'Average Seizure Length Z-score'] *5\n",
    "\n",
    "    for key in condition_dictionary.keys():\n",
    "        \n",
    "        if key[0] != 'F':\n",
    "            \n",
    "            continue\n",
    "    \n",
    "        new_vals = []\n",
    "    \n",
    "        for condition, measurement, value in zip(list(compiled_df['Condition'].values), list(compiled_df['Measurement'].values), list(compiled_df[key].values)):\n",
    "\n",
    "            new_vals.append(value)\n",
    "\n",
    "            if measurement == 'Time in Seizure (s)':\n",
    "\n",
    "                dict_choice = time_mean_sd\n",
    "\n",
    "            elif measurement == '# Seizures':\n",
    "\n",
    "                dict_choice = seizure_count_mean_sd\n",
    "\n",
    "            elif measurement == 'Average Seizure Length':\n",
    "\n",
    "                dict_choice = avg_mean_sd\n",
    "\n",
    "            #calculating z-scores:\n",
    "\n",
    "            mean = dict_choice[condition][1]\n",
    "\n",
    "            sd = dict_choice[condition][0]\n",
    "            \n",
    "            if sd != 0:\n",
    "                \n",
    "                new_vals.append((value - mean)/sd)\n",
    "\n",
    "            else:\n",
    "\n",
    "                new_vals.append(0)\n",
    "    \n",
    "        final_dictionary[key] = new_vals\n",
    "        \n",
    "    return final_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713e5bbe-5fc1-4396-950e-d323ad5ae0cc",
   "metadata": {},
   "source": [
    "**FILE UPLOAD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdb94fe-fc57-4fbc-9e95-345558d022d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pathname = '[insert path here]'\n",
    "\n",
    "folder1 = os.fsencode(path1)\n",
    "\n",
    "all_trials = {}\n",
    "\n",
    "for file in os.listdir(folder1):\n",
    "    file_name = file.decode(\"utf-8\")\n",
    "\n",
    "    if file_name == \".DS_Store\":\n",
    "        continue\n",
    "        \n",
    "    filenames = []\n",
    "\n",
    "    path2 = pathname + '/' + file_name\n",
    "    folder2 = os.fsencode(path2)\n",
    "    for file2 in os.listdir(folder2):\n",
    "        filename = os.fsdecode(file2)\n",
    "        if filename == \".DS_Store\":\n",
    "            continue\n",
    "             \n",
    "        filenames.append(filename)\n",
    "    all_trials[file_name] = filenames\n",
    "    \n",
    "all_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6500e4f7-1fa1-42a7-8c67-626158ada488",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial in all_trials:\n",
    "\n",
    "    file_names = all_trials[trial]\n",
    "    \n",
    "    for file in file_names: \n",
    "        \n",
    "        if 'water' in file and 'pro' in file:\n",
    "            \n",
    "            watercsv = pathname +  '/' + trial + '/' + file\n",
    "\n",
    "        elif 'baseline' in file and 'pro' in file:\n",
    "            \n",
    "            baselinecsv = pathname +  '/' +  trial + '/' + file\n",
    "\n",
    "        elif '1mM' in file and 'pro' in file:\n",
    "            \n",
    "            onecsv = pathname +   '/' + trial + '/' + file\n",
    "\n",
    "        elif '2mM' in file and 'pro' in file:\n",
    "            \n",
    "            twocsv = pathname +  '/' +  trial + '/' + file\n",
    "\n",
    "        elif '5mM' in file and 'pro' in file:\n",
    "            \n",
    "            fivecsv = pathname +  '/' +  trial + '/' + file\n",
    "\n",
    "        elif 'genotype' in file and 'pro' in file:\n",
    "            \n",
    "            gen = pathname +  '/' +  trial + '/' + file\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    categories_dictionary = categories(gen)\n",
    "    print(trial)\n",
    "\n",
    "    base = thresh_data_processing(baselinecsv, baselinecsv, gen)\n",
    "    water = thresh_data_processing(watercsv, baselinecsv, gen)\n",
    "    one = thresh_data_processing(onecsv, baselinecsv, gen)\n",
    "    two = thresh_data_processing(twocsv, baselinecsv, gen)\n",
    "    five = thresh_data_processing(fivecsv, baselinecsv, gen)\n",
    "\n",
    "    compiled_df = compile_df(base, water, one, two, five)\n",
    "\n",
    "    wt_dict, het_dict, null_dict = separate_genotypes(compiled_df, categories_dictionary)\n",
    "    wt_df = pd.DataFrame(wt_dict)\n",
    "    het_df = pd.DataFrame(het_dict)\n",
    "    null_df = pd.DataFrame(null_dict)\n",
    "\n",
    "    # WT\n",
    "    wt_new_dict = add_z_score(wt_dict, wt_df)\n",
    "    new_wt_df = pd.DataFrame(wt_new_dict).transpose()\n",
    "        \n",
    "    filepath = Path(pathname +  trial + '/WT.csv')  \n",
    "    filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "    new_wt_df.to_csv(filepath)  \n",
    "\n",
    "    # HET \n",
    "    het_new_dict = add_z_score(het_dict, wt_df)\n",
    "    new_het_df = pd.DataFrame(het_new_dict).transpose()\n",
    "        \n",
    "    filepath = Path(pathname +  trial + '/HET.csv')  \n",
    "    filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "    new_het_df.to_csv(filepath)\n",
    "\n",
    "    # NULL \n",
    "    null_new_dict = add_z_score(null_dict, wt_df)\n",
    "    new_null_df = pd.DataFrame(null_new_dict).transpose()\n",
    "        \n",
    "    filepath = Path(pathname +  trial + '/NULL.csv')  \n",
    "    filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "    new_null_df.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b1cda3-b835-4199-88ac-225ed5fb0658",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial in all_trials:\n",
    "\n",
    "    file_names = all_trials[trial]\n",
    "\n",
    "    pathname = '/Users/junipolansky/zebrafish_PTZ/PTZ_final_files/'\n",
    "    \n",
    "    for file in file_names: \n",
    "        \n",
    "        if 'water' in file and 'pro' in file:\n",
    "            \n",
    "            watercsv = pathname +  trial + '/' + file\n",
    "\n",
    "        elif 'baseline' in file and 'pro' in file:\n",
    "            \n",
    "            baselinecsv = pathname +  trial + '/' + file\n",
    "\n",
    "        elif '1mM' in file and 'pro' in file:\n",
    "            \n",
    "            onecsv = pathname +  trial + '/' + file\n",
    "\n",
    "        elif '2mM' in file and 'pro' in file:\n",
    "            \n",
    "            twocsv = pathname +  trial + '/' + file\n",
    "\n",
    "        elif '5mM' in file and 'pro' in file:\n",
    "            \n",
    "            fivecsv = pathname +  trial + '/' + file\n",
    "\n",
    "        elif 'genotype' in file and 'pro' in file:\n",
    "            \n",
    "            gen = pathname +  trial + '/' + file\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    categories_dictionary = categories(gen)\n",
    "    print(trial)\n",
    "\n",
    "    base = thresh_data_processing(baselinecsv, baselinecsv, gen)\n",
    "    water = thresh_data_processing(watercsv, baselinecsv, gen)\n",
    "    one = thresh_data_processing(onecsv, baselinecsv, gen)\n",
    "    two = thresh_data_processing(twocsv, baselinecsv, gen)\n",
    "    five = thresh_data_processing(fivecsv, baselinecsv, gen)\n",
    "\n",
    "    compiled_df = compile_df(base, water, one, two, five)\n",
    "\n",
    "    wt_dict, het_dict, null_dict = separate_genotypes(compiled_df, categories_dictionary)\n",
    "    wt_df = pd.DataFrame(wt_dict)\n",
    "    het_df = pd.DataFrame(het_dict)\n",
    "    null_df = pd.DataFrame(null_dict)\n",
    "\n",
    "    # WT\n",
    "    wt_new_dict = add_z_score(wt_dict, wt_df)\n",
    "    new_wt_df = pd.DataFrame(wt_new_dict).transpose()\n",
    "        \n",
    "    filepath = Path(pathname +  trial + '/WT2.csv')  \n",
    "    filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "    new_wt_df.to_csv(filepath)  \n",
    "\n",
    "    # HET \n",
    "    het_new_dict = add_z_score(het_dict, wt_df)\n",
    "    new_het_df = pd.DataFrame(het_new_dict).transpose()\n",
    "        \n",
    "    filepath = Path(pathname +  trial + '/HET2.csv')  \n",
    "    filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "    new_het_df.to_csv(filepath)\n",
    "\n",
    "    # NULL \n",
    "    null_new_dict = add_z_score(null_dict, wt_df)\n",
    "    new_null_df = pd.DataFrame(null_new_dict).transpose()\n",
    "        \n",
    "    filepath = Path(pathname +  trial + '/NULL2.csv')  \n",
    "    filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "    new_null_df.to_csv(filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
